---
layout:     post
title:      “SourceRank.org - Open-source quality assessment of news media publications“
date:       2018-02-16
summary:  Our Facebook Hack 2018 project
categories: software-engineering fake-news news-media
---

![INCLUDE THE PICTURE]()

For the 2018 [Facebook Melbourne Hackathon](https://www.facebook.com/events/432440330543435/), me and three other RMIT students ([Callan](https://github.com/zcallan), [Matt](https://github.com/matthaywardwebdesign), and Michael) built the sourcerank.org platform, and MVP implementation of an open tool for news and information quality evaluation. At presentation time, our platform included a web app (www.sourcerank.org), a [basic Facebook Messenger bot](https://www.messenger.com/t/166585247361466), a Chrome extension, and a public api (www.sourcerank.org/api/). Though we didn’t place, probably due to a bungled presentation, I think the idea has merit and the design and implementation was interesting enough to warrant further description. The following I hope gives a clear understanding of the thinking behind sourcerank.org, the immediate utility of our polished up ‘source rank 0.2’ implementation, and of a longer term vision for open-source, community-driven information quality evaluation tooling.

### The Problem
‘Fake News’ has become a pretty prominent problem in the media lately, but more broadly, social media has become a powerful vector for low-quality and even malicious media that while not outright ‘fake’ or ‘false’, is a burden on the information systems it finds itself in.

Because of it’s significance in the 2016 US election, public and political consciousness around this issue has been raised and thus the giant tech companies like Facebook and Google has initiated or ramped up their efforts to maintain ‘information quality’ on their platforms. We included [this quote by Mark Zuckerberg](https://clyp.it/ugvvtt1e#) in our presentation, taken from [his April appearance on The Ezra Klein podcast](https://art19.com/shows/the-ezra-klein-show/episodes/0d5f503d-80d0-4e98-aa08-d29599957459). In it Zuckerberg details efforts to survey their user base in order to discover which new sources were broadly understood by their users to be trustworthy. The motivation here is to establish a ‘common ground’ and ‘shared understanding’ between polarised peoples. If Facebook can get a signal on what in untrustworthy and ban it, and also get a signal on what their users are willing to agree is credible, they get a better information system. I think this is a great goal, and one that I wanted to tackle, but from a different direction.

### Progress Towards A Solution
The **major** problem that I see with Facebook’s current approach to the problem is that it is internal and inaccessible. When Facebook do these surveys, they don’t publish their methodology and they don’t publish their results. Facebook, and Google, are regularly criticised for keeping their approaches to platform content maintenance and censorship private. Here’s [one recent example article](https://techcrunch.com/2018/05/07/santa-clara-principles-eff-cdt-aclu-facebook-google-twitter/). The reasons for the criticism are clear. Without an open-approach they lack accountability, oversight, and *user involvement*. Facebook obviously sees the value in involving users in part of the process (they surveyed them), but it would be better if the public were involved in the *whole process*, the entire overall endeavour of cleaning up our information systems.

Noting this problem, our solution, sourcerank.org, is designed to be open-source, open-methodology, open to feedback, and open to user  configuration.

The second clear problem with Facebook’s approach of surveying users for their opinions on news trustworthiness is an important one, but one that perhaps sits uncomfortably with Facebook (and Google). It is the problem that users may have *bad reasons for trusting a news media site*. In audio clip linked up above, Zuckerberg calls out *The New York Times*, and *The Wall Street Journal* as two site that are ‘broadly trusted’, even by those that don’t typically agree with those publication’s content. The mentioning of those names is assuring, but given their methodology it is entirely possible that ridiculous sites like *The Daily Stormer* and *Info Wars* may have come up as most trustworthy amongst users. We could certainly imagine that happening if this kind of surveying was conducted on the alt-right-wing platform [voat.com](https://voat.co/). Would Facebook have been happy to run with their results if their users had communicated to them that *Breitbart.com* was unassailably trustworthy and that *The New York Times* was a “traitorous (((globalist))) rag”? It is better, I believe, to have userbases settle on *why* publications are trustworthy, *what makes them trustworthy*, rather than merely on which publications they think are trustworthy.

My interest then centres on the high-level *features* of good information and trustworthy news. This is because while a complete, infallible, description of news quality and trustworthiness is an incredibly complicated thing to mark out, the general idea can be broken down into more specific components. There are dozens of ‘signals’ that contribute to an assessment  of quality in a person’s mind, and each of those signals tracks some slice of the news quality pie. I believe a number of these ‘signals’ (or ‘heuristics’) can be picked out and ‘computerised’, creating an automated system of information quality monitoring and evaluation. Our team’s platform, sourcerank.org, is basically an open system for the conglomeration of algorithmic news-quality heuristics that assesses whether a *publication* is good, a system in the same family as one described [this article by Stanford John S. Knight Fellow, Frederic Filloux](https://mondaynote.com/dealing-with-an-elusive-corpus-of-news-stories-ea039f9db914) for evaluating the content of *specific articles*.

### The SourceRank System

SourceRank’s core contention is that an acceptably accurate assessment of news and information quality can be made by the intelligent composition of human-engineered heuristics, rather that opting to employ behind-the-scenes, black-box machine learning models. In the hackathon our team took this contention and hoped to support it by the building of a core engine that ingests data about news publications and feeds it into heuristic algorithms. The results of this then get stored in a database for serving over a public API, www.sourcerank.com/api/. To showcase the opportunity afforded by an open API and open platform, we used the API to drive a Facebook Messenger Bot, a Chrome Extension, and a website. Once our core heuristic engine was built, our open model meant that we (and others) could immediately start installing it’s utility anywhere and everywhere. Actually, we even made it available over SMS at +61 447 528 181.

#### SourceRank’s Heuristics
The quality of the design and implementation of the heuristics are what obviously mostly drives the utility of our system, and only having 24 hours, we admittedly had to start simple. Here’s a some of the earliest implemented:

* “I trust the experts” - What proportion of contributors to the publication are academics?  (Used `newspaper3k` and Google Scholar for the algorithm)
* “I want to avoid click-funded content” - Does the publication make a paid subscription model available? (Data was *manually* gathered)
* “I want to avoid highly biased content” - Does the publication have a strong left/right political bias (Data was scraped from mediabiasfactcheck.com)

Each of these are pretty rudimentary, and the first one had some weaknesses in it’s implementation due to a lack of [record linkage](https://en.wikipedia.org/wiki/Record_linkage)  (eg. Michael Jordan the academic and Michael Jordan the basketballer).  However, when combined even these vary basic heuristics produce a pretty plausible ranking. With further investment of time, better heuristics could be produced and existing ones improved, until what existed was an acceptably reliable information quality evaluation tool.

#### Human Engineered > ML model
Better yet, our system would have the following very attractive qualities:

* Interpretability - compared with particularly statistical language models, our human-engineered heuristic based score is very easy for an average user to understand and inspect.
* Configurability & Compose-ability - it’s quite hard to ‘cut out’ a bit of a machine learning model, and it’s also often not a good idea to combine them ad-hoc. With sourcerank.org, it’s easy to envisage user’s being able pick and choose certain heuristics, and weight those heuristics relative to each other

ML-dominated approaches are currently struggling to possess the above characteristics, certainly the first. Further to the point, ML itself seems currently no where near capable of grokking news quality in any satisfactory way. People have tried to wield it against ‘fake news’, and often [the results are highly discouraging](http://www.thundergolfer.com/machine-learning/nlp/fake-news/news-media/2018/04/24/fake-news-and-nlp-stupidity/).
